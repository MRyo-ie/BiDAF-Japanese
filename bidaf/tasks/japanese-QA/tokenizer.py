

def tokenize_Japanese(sequence):
    """
    日本語の Tokenizer
    ・ Sentence Piece
    ・ mecab
    の両方使えるようにする予定。
    """
    print('日本語')
